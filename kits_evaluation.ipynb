{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h1>Evaluation</h3>\n",
    "Here we will Evaluate the results of teh segmentation on three metrics: Dice-Score, HD95-Score, ASSD-Score. HD95 and ASSD depend on the target spacing which is why we have to specify the traget spacing of the model we want to evaluate"
   ],
   "id": "763afa6a5763e09e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "target_spacing=(1.0, 1.0, 1.0)",
   "id": "4c16be9a247304a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h3>Native Spacing</h3>\n",
    "First we evaluate the model on the images with the native resolution"
   ],
   "id": "4b25b8ec5c681a42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T12:15:20.127750Z",
     "start_time": "2025-07-31T12:14:56.302808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from panoptica import Panoptica_Statistic, InputType, Panoptica_Evaluator,Panoptica_Aggregator, ConnectedComponentsInstanceApproximator, NaiveThresholdMatching\n",
    "from panoptica.metrics import Metric\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import sys\n",
    "# Add script directory to Python path\n",
    "module_path = r\"KiTS23/scripts\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import resample_to_target\n",
    "importlib.reload(resample_to_target)\n",
    "\n",
    "from resample_to_target import resample_dataset"
   ],
   "id": "5166fae1d6f488bb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\panoptica\\panoptica_aggregator.py:19: UserWarning:\n",
      "\n",
      "The multiprocessing start method has been set to 'spawn' since 'fork' is not available on Windows. This can lead to thread unsafety in the current development state.\n",
      "\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\asyncio\\base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\asyncio\\base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\Temp\\ipykernel_26248\\698033931.py\", line 2, in <module>\n",
      "    from panoptica import Panoptica_Statistic, InputType, Panoptica_Evaluator,Panoptica_Aggregator, ConnectedComponentsInstanceApproximator, NaiveThresholdMatching\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\panoptica\\__init__.py\", line 7, in <module>\n",
      "    from panoptica.panoptica_aggregator import Panoptica_Aggregator\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\jeanb\\AppData\\Local\\anaconda3\\envs\\ADLM\\Lib\\site-packages\\panoptica\\panoptica_aggregator.py\", line 19, in <module>\n",
      "    warnings.warn(\n",
      "####################################\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Enter the path to your predictions\n",
    "pred_dir = \"KiTS23/predictions/original_resolution\"\n",
    "\n",
    "# Enter the path to your ground truths\n",
    "gt_dir = \"KiTS23/dataset/nnUNet_data/test/nnUNet_raw/Dataset220_KiTS2023/labelsTr\"\n",
    "\n",
    "output_file = \"KiTS23/evaluation/evaluation_native.tsv\"\n",
    "\n",
    "# Enter the voxel spacing of your model (the one that was used to get the predictions)\n",
    "voxel_spacing = (1.0, 1.0, 1.0)"
   ],
   "id": "6a8b1b190b303477"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === Collect all case names from the ground truth folder ===\n",
    "case_ids = sorted([\n",
    "    f.replace(\".nii.gz\", \"\")\n",
    "    for f in os.listdir(gt_dir)\n",
    "    if f.endswith(\".nii.gz\")\n",
    "])\n",
    "\n",
    "# === Create PAIR ===\n",
    "PAIR = []\n",
    "\n",
    "for case_id in case_ids:\n",
    "    pred_path = os.path.join(pred_dir, case_id + \".nii.gz\")\n",
    "    gt_path = os.path.join(gt_dir, case_id + \".nii.gz\")\n",
    "\n",
    "    if not os.path.exists(pred_path):\n",
    "        print(f\"[Warning] Prediction for {case_id} not found, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load prediction and GT\n",
    "    pred_img = nib.load(pred_path)\n",
    "    gt_img = nib.load(gt_path)\n",
    "\n",
    "    pred = pred_img.get_fdata().astype(np.uint8)\n",
    "    mask = gt_img.get_fdata().astype(np.uint8)\n",
    "\n",
    "    # Optional: check shape match\n",
    "    if pred.shape != mask.shape:\n",
    "        print(f\"[Error] Shape mismatch in {case_id}: pred {pred.shape}, gt {mask.shape}\")\n",
    "        continue\n",
    "\n",
    "    PAIR.append((pred, mask, case_id))\n",
    "\n",
    "print(f\"Loaded {len(PAIR)} pairs for evaluation.\")\n",
    "\n",
    "evaluator = Panoptica_Aggregator(\n",
    "    Panoptica_Evaluator.load_from_config(\"KiTS23/scripts/panoptica_evaluator_kits23.yaml\"),\n",
    "    output_file = output_file,\n",
    "    log_times = True,\n",
    "    continue_file = True,\n",
    ")\n",
    "\n",
    "for pred, gt, case in PAIR:\n",
    "    evaluator.evaluate(pred, gt, case, voxelspacing=voxel_spacing)"
   ],
   "id": "440cff1bde34b192"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h3>Target Spacing</h3>\n",
    "Now we evaluate the model on the images with the target resolution. We have to resample the ground thruths to the target resolution aswell."
   ],
   "id": "63ab16cf39243e28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T12:09:09.181122Z",
     "start_time": "2025-07-31T12:09:02.140459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add script directory to Python path\n",
    "module_path = r\"KiTS23/scripts\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Define input folder and target spacing\n",
    "input_folder = \"KiTS23/dataset/nnUNet_data/test/nnUNet_raw/Dataset220_KiTS2023/labelsTr\"\n",
    "target_spacing = (2.0, 2.0, 2.0)\n",
    "\n",
    "# Call the function\n",
    "resample_dataset(\n",
    "    input_folder=input_folder,\n",
    "    target_spacing=target_spacing,\n",
    "    seg=True\n",
    ")"
   ],
   "id": "381b6b4339428b35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved output path: KiTS23\\dataset\\nnUNet_data\\test\\nnUNet_raw_resampled\\Dataset220_KiTS2023\\labelsTr\n",
      "Found 1 images to resample to spacing (2.0, 2.0, 2.0)\n",
      "\n",
      "case_00000.nii.gz: original spacing = (0.5, 0.9199219, 0.9199219)\n",
      "\u001B[96m[*] Save KiTS23\\dataset\\nnUNet_data\\test\\nnUNet_raw_resampled\\Dataset220_KiTS2023\\labelsTr\\case_00000.nii.gz as uint8\u001B[0m\u001B[0m\n",
      "Saved resampled image to: KiTS23\\dataset\\nnUNet_data\\test\\nnUNet_raw_resampled\\Dataset220_KiTS2023\\labelsTr\\case_00000.nii.gz\n",
      "\n",
      "All images resampled and saved to: KiTS23\\dataset\\nnUNet_data\\test\\nnUNet_raw_resampled\\Dataset220_KiTS2023\\labelsTr\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we do the evaluation on the target resolution",
   "id": "50f5bd221c90ecc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T12:23:05.870621Z",
     "start_time": "2025-07-31T12:23:05.796408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enter the path to your predictions\n",
    "pred_dir = \"KiTS23/predictions/target_resolution\"\n",
    "\n",
    "# Enter the path to your ground truths\n",
    "gt_dir = \"KiTS23/dataset/nnUNet_data/test/nnUNet_raw_resampled/Dataset220_KiTS2023/labelsTr\"\n",
    "\n",
    "output_file = \"KiTS23/evaluation/evaluation_tsv/evaluation_target.tsv\"\n",
    "\n",
    "# Enter the voxel spacing of your model (the one that was used to get the predictions)\n",
    "voxel_spacing = (2.0, 2.0, 2.0)"
   ],
   "id": "fe298c7a23d4f7b9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T12:36:54.828435Z",
     "start_time": "2025-07-31T12:36:54.361185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Collect all case names from the ground truth folder ===\n",
    "case_ids = sorted([\n",
    "    f.replace(\".nii.gz\", \"\")\n",
    "    for f in os.listdir(gt_dir)\n",
    "    if f.endswith(\".nii.gz\")\n",
    "])\n",
    "\n",
    "# === Create PAIR ===\n",
    "PAIR = []\n",
    "\n",
    "for case_id in case_ids:\n",
    "    pred_path = os.path.join(pred_dir, case_id + \".nii.gz\")\n",
    "    gt_path = os.path.join(gt_dir, case_id + \".nii.gz\")\n",
    "\n",
    "    if not os.path.exists(pred_path):\n",
    "        print(f\"[Warning] Prediction for {case_id} not found, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load prediction and GT\n",
    "    pred_img = nib.load(pred_path)\n",
    "    gt_img = nib.load(gt_path)\n",
    "\n",
    "    pred = pred_img.get_fdata().astype(np.uint8)\n",
    "    mask = gt_img.get_fdata().astype(np.uint8)\n",
    "\n",
    "    # Optional: check shape match\n",
    "    if pred.shape != mask.shape:\n",
    "        print(f\"[Error] Shape mismatch in {case_id}: pred {pred.shape}, gt {mask.shape}\")\n",
    "        continue\n",
    "\n",
    "    PAIR.append((pred, mask, case_id))\n",
    "\n",
    "print(f\"Loaded {len(PAIR)} pairs for evaluation.\")\n",
    "\n",
    "evaluator = Panoptica_Aggregator(\n",
    "    Panoptica_Evaluator.load_from_config(\"KiTS23/scripts/panoptica_evaluator_kits23.yaml\"),\n",
    "    output_file = output_file,\n",
    "    log_times = True,\n",
    "    continue_file = True,\n",
    ")\n",
    "\n",
    "for pred, gt, case in PAIR:\n",
    "    evaluator.evaluate(pred, gt, case, voxelspacing=voxel_spacing)\n"
   ],
   "id": "e952f2df12aab811",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 pairs for evaluation.\n",
      "The same labels [2, 3] were assigned to two different labelgroups, got SegmentationClassGroups = \n",
      " - kidney : LabelMergeGroup [1, 2, 3] -> ONE, single_instance=False\n",
      " - masses : LabelMergeGroup [2, 3] -> ONE, single_instance=False\n",
      " - tumor : LabelGroup [2], single_instance=True\n",
      "Intended? This will evaluate the duplicate labels in both groups\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Panoptica_Aggregator.evaluate() got an unexpected keyword argument 'voxelspacing'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 43\u001B[39m\n\u001B[32m     35\u001B[39m evaluator = Panoptica_Aggregator(\n\u001B[32m     36\u001B[39m     Panoptica_Evaluator.load_from_config(\u001B[33m\"\u001B[39m\u001B[33mKiTS23/scripts/panoptica_evaluator_kits23.yaml\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m     37\u001B[39m     output_file = output_file,\n\u001B[32m     38\u001B[39m     log_times = \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m     39\u001B[39m     continue_file = \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m     40\u001B[39m )\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m pred, gt, case \u001B[38;5;129;01min\u001B[39;00m PAIR:\n\u001B[32m---> \u001B[39m\u001B[32m43\u001B[39m     evaluator.evaluate(pred, gt, case, voxelspacing=voxel_spacing)\n",
      "\u001B[31mTypeError\u001B[39m: Panoptica_Aggregator.evaluate() got an unexpected keyword argument 'voxelspacing'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "81583252ad716d72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
